# import tensorflow as tf 
# from tensorflow import keras
# from tensorflow.keras.preprocessing.text import Tokenizer

# sentences = [
#     "toi yeu mina",
#     "toi yeu yen"
# ]

# tkenizer = Tokenizer(num_words=100)
# tkenizer.fit_on_texts(sentences)

# word_index = tkenizer.word_index
# print(word_index)